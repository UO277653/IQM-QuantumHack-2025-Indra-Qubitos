{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battlefield Tester Explained\n",
    "\n",
    "This notebook explains the comprehensive testing framework for analyzing battlefield performance.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The tester runs multiple battles and generates detailed analytics:\n",
    "- Victory distributions\n",
    "- Win rates by team size\n",
    "- Battle timelines  \n",
    "- Initial configuration comparisons\n",
    "- Comprehensive visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../testing_battlefield')\n",
    "\n",
    "from battlefield_tester import BattlefieldTester\n",
    "import quantum_library as qlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test Types\n",
    "\n",
    "The framework provides 4 test types:\n",
    "\n",
    "1. **Random Composition**: Completely random team compositions\n",
    "2. **Balance Test**: Predefined balanced compositions\n",
    "3. **Performance Test**: Mix of random and balanced for statistics\n",
    "4. **Initial Configuration Test**: Tests different starting positions (Face to Face, Surrounded, Random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up a Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tester\n",
    "tester = BattlefieldTester(\n",
    "    num_battles=30,      # Number of battles to simulate\n",
    "    max_turns=50,        # Max turns before declaring draw\n",
    "    grid_size=(4, 4)     # Battlefield dimensions\n",
    ")\n",
    "\n",
    "print(f\"Tester configured:\")\n",
    "print(f\"  Battles: {tester.num_battles}\")\n",
    "print(f\"  Max turns: {tester.max_turns}\")\n",
    "print(f\"  Grid: {tester.grid_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating Team Compositions\n",
    "\n",
    "Compositions define team makeup: `{unit_type: (count, strength, health, range)}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random composition\n",
    "random_comp = tester.generate_random_composition(max_units=8)\n",
    "print(\"Random composition:\")\n",
    "for unit_type, (count, strength, health, range_dist) in random_comp.items():\n",
    "    print(f\"  {count}x {unit_type}: STR={strength}, HP={health}, RNG={range_dist}\")\n",
    "\n",
    "# Predefined balanced compositions\n",
    "balanced_comps = tester.get_balanced_compositions()\n",
    "print(f\"\\nAvailable balanced compositions: {len(balanced_comps)}\")\n",
    "for i, (q_comp, c_comp, desc) in enumerate(balanced_comps[:3]):\n",
    "    print(f\"{i+1}. {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Tests\n",
    "\n",
    "### Test 1: Random Compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set quantum method\n",
    "qlib.set_quantum_method(\"exact\")  # Use fast method for demo\n",
    "\n",
    "# Run random composition test (small number for demo)\n",
    "tester_random = BattlefieldTester(num_battles=10, max_turns=50, grid_size=(4, 4))\n",
    "tester_random.test_random_compositions()\n",
    "\n",
    "print(f\"\\nCompleted {len(tester_random.results)} battles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Initial Configurations (NEW!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run initial configuration test\n",
    "tester_config = BattlefieldTester(num_battles=9, max_turns=50, grid_size=(4, 4))\n",
    "tester_config.test_initial_configurations()\n",
    "\n",
    "# Analyze by configuration\n",
    "configs = {}\n",
    "for result in tester_config.results:\n",
    "    config = result.initial_config\n",
    "    if config not in configs:\n",
    "        configs[config] = {'quantum': 0, 'classical': 0, 'draw': 0}\n",
    "    \n",
    "    if result.winner == 'Quantum':\n",
    "        configs[config]['quantum'] += 1\n",
    "    elif result.winner == 'Classical':\n",
    "        configs[config]['classical'] += 1\n",
    "    else:\n",
    "        configs[config]['draw'] += 1\n",
    "\n",
    "print(\"\\nResults by configuration:\")\n",
    "for config, wins in configs.items():\n",
    "    total = sum(wins.values())\n",
    "    q_pct = wins['quantum'] / total * 100 if total > 0 else 0\n",
    "    print(f\"  {config}: Quantum {wins['quantum']}/{total} ({q_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Results\n",
    "\n",
    "Results are stored as `BattleResult` objects with detailed statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first result\n",
    "if tester_config.results:\n",
    "    result = tester_config.results[0]\n",
    "    print(f\"Battle {result.battle_id}:\")\n",
    "    print(f\"  Winner: {result.winner}\")\n",
    "    print(f\"  Duration: {result.turns} turns ({result.duration_seconds:.2f}s)\")\n",
    "    print(f\"  Initial config: {result.initial_config}\")\n",
    "    print(f\"  Quantum: {result.quantum_initial_count} → {result.quantum_survivors}\")\n",
    "    print(f\"  Classical: {result.classical_initial_count} → {result.classical_survivors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "tester_config.print_summary_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizations\n",
    "\n",
    "The tester generates comprehensive dashboards with 6 plots:\n",
    "1. Victory Distribution (pie chart)\n",
    "2. Win Rate by Team Size\n",
    "3. Battle Outcome Timeline\n",
    "4. **Win Rate by Initial Configuration** (NEW!)\n",
    "5. **Battle Duration by Configuration** (NEW!)\n",
    "6. Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plots (saves to file and displays)\n",
    "tester_config.generate_comprehensive_plots()\n",
    "# This will save to 'battlefield_test_results.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Command Line Usage\n",
    "\n",
    "The tester can also be run from command line:\n",
    "\n",
    "```bash\n",
    "cd testing_battlefield\n",
    "\n",
    "# Test 1: Random compositions\n",
    "python battlefield_tester.py --test 1 --battles 100\n",
    "\n",
    "# Test 2: Balanced compositions\n",
    "python battlefield_tester.py --test 2 --battles 100\n",
    "\n",
    "# Test 3: Performance metrics\n",
    "python battlefield_tester.py --test 3 --battles 200\n",
    "\n",
    "# Test 4: Initial configurations\n",
    "python battlefield_tester.py --test 4 --battles 99\n",
    "\n",
    "# Custom grid size\n",
    "python battlefield_tester.py --test 4 --battles 99 --grid-width 6 --grid-height 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparing EXACT vs QAOA\n",
    "\n",
    "You can easily compare both quantum methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with EXACT method\n",
    "qlib.set_quantum_method(\"exact\")\n",
    "tester_exact = BattlefieldTester(num_battles=10, max_turns=50, grid_size=(4, 4))\n",
    "tester_exact.test_random_compositions()\n",
    "\n",
    "quantum_wins_exact = sum(1 for r in tester_exact.results if r.winner == 'Quantum')\n",
    "avg_turns_exact = sum(r.turns for r in tester_exact.results) / len(tester_exact.results)\n",
    "\n",
    "print(f\"EXACT Method Results:\")\n",
    "print(f\"  Quantum wins: {quantum_wins_exact}/10 ({quantum_wins_exact*10}%)\")\n",
    "print(f\"  Avg turns: {avg_turns_exact:.2f}\")\n",
    "\n",
    "# Test with QAOA method (WARNING: Will be slower!)\n",
    "# Uncomment to run:\n",
    "# qlib.set_quantum_method(\"qaoa\")\n",
    "# qlib.QAOA_P = 1\n",
    "# qlib.QAOA_N_RESTARTS = 2\n",
    "# tester_qaoa = BattlefieldTester(num_battles=10, max_turns=50, grid_size=(4, 4))\n",
    "# tester_qaoa.test_random_compositions()\n",
    "#\n",
    "# quantum_wins_qaoa = sum(1 for r in tester_qaoa.results if r.winner == 'Quantum')\n",
    "# avg_turns_qaoa = sum(r.turns for r in tester_qaoa.results) / len(tester_qaoa.results)\n",
    "#\n",
    "# print(f\"\\nQAOA Method Results (p=1, n_restarts=2):\")\n",
    "# print(f\"  Quantum wins: {quantum_wins_qaoa}/10 ({quantum_wins_qaoa*10}%)\")\n",
    "# print(f\"  Avg turns: {avg_turns_qaoa:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Custom Analysis\n",
    "\n",
    "You can access raw results for custom analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if tester_exact.results:\n",
    "    # Custom statistics\n",
    "    turns = [r.turns for r in tester_exact.results]\n",
    "    durations = [r.duration_seconds for r in tester_exact.results]\n",
    "    \n",
    "    print(\"Custom Statistics:\")\n",
    "    print(f\"  Turn distribution: min={min(turns)}, max={max(turns)}, median={np.median(turns):.1f}\")\n",
    "    print(f\"  Duration: min={min(durations):.2f}s, max={max(durations):.2f}s\")\n",
    "    \n",
    "    # Survival rates\n",
    "    quantum_survival = [r.quantum_survivors / r.quantum_initial_count \n",
    "                       for r in tester_exact.results if r.quantum_initial_count > 0]\n",
    "    if quantum_survival:\n",
    "        print(f\"  Quantum avg survival rate: {np.mean(quantum_survival)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Components**:\n",
    "- `BattlefieldTester`: Main testing framework\n",
    "- `BattleResult`: Stores individual battle statistics\n",
    "\n",
    "**Test Types**:\n",
    "1. Random Compositions\n",
    "2. Balanced Compositions\n",
    "3. Performance Metrics\n",
    "4. Initial Configurations (Face to Face, Surrounded, Random)\n",
    "\n",
    "**Outputs**:\n",
    "- Console summary statistics\n",
    "- Comprehensive 6-panel visualization dashboard\n",
    "- Raw results for custom analysis\n",
    "\n",
    "**Configuration**:\n",
    "- Set quantum method in `quantum_library.py` or via `set_quantum_method()`\n",
    "- Adjust QAOA parameters for quality/speed tradeoff\n",
    "- See `QUANTUM_CONFIG.md` for detailed configuration guide\n",
    "\n",
    "**Next Steps**:\n",
    "- Run large-scale tests with `--battles 1000`\n",
    "- Compare EXACT vs QAOA performance\n",
    "- Analyze specific configurations\n",
    "- Tune QAOA parameters for optimal results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
